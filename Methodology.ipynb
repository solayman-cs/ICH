{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_applications import get_submodules_from_kwargs\n",
    "\n",
    "from ._common_blocks import Conv2dBn\n",
    "from ._utils import freeze_model, filter_keras_submodules\n",
    "from ..backbones.backbones_factory import Backbones\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Utility functions\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def get_submodules():\n",
    "    return {\n",
    "        'backend': backend,\n",
    "        'models': models,\n",
    "        'layers': layers,\n",
    "        'utils': keras_utils,\n",
    "    }\n",
    "\n",
    "\n",
    "def check_input_shape(input_shape, factor):\n",
    "    if input_shape is None:\n",
    "        raise ValueError(\"Input shape should be a tuple of 3 integers, not None!\")\n",
    "\n",
    "    h, w = input_shape[:2] if backend.image_data_format() == 'channels_last' else input_shape[1:]\n",
    "    min_size = factor * 6\n",
    "\n",
    "    is_wrong_shape = (\n",
    "            h % min_size != 0 or w % min_size != 0 or\n",
    "            h < min_size or w < min_size\n",
    "    )\n",
    "\n",
    "    if is_wrong_shape:\n",
    "        raise ValueError('Wrong shape {}, input H and W should '.format(input_shape) +\n",
    "                         'be divisible by `{}`'.format(min_size))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Blocks\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def Conv1x1BnReLU(filters, use_batchnorm, name=None):\n",
    "    kwargs = get_submodules()\n",
    "\n",
    "    def wrapper(input_tensor):\n",
    "        return Conv2dBn(\n",
    "            filters,\n",
    "            kernel_size=1,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_uniform',\n",
    "            padding='same',\n",
    "            use_batchnorm=use_batchnorm,\n",
    "            name=name,\n",
    "            **kwargs\n",
    "        )(input_tensor)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def SpatialContextBlock(\n",
    "        level,\n",
    "        conv_filters=512,\n",
    "        pooling_type='avg',\n",
    "        use_batchnorm=True,\n",
    "):\n",
    "    if pooling_type not in ('max', 'avg'):\n",
    "        raise ValueError('Unsupported pooling type - `{}`.'.format(pooling_type) +\n",
    "                         'Use `avg` or `max`.')\n",
    "\n",
    "    Pooling2D = layers.MaxPool2D if pooling_type == 'max' else layers.AveragePooling2D\n",
    "\n",
    "    pooling_name = 'psp_level{}_pooling'.format(level)\n",
    "    conv_block_name = 'psp_level{}'.format(level)\n",
    "    upsampling_name = 'psp_level{}_upsampling'.format(level)\n",
    "\n",
    "    def wrapper(input_tensor):\n",
    "        # extract input feature maps size (h, and w dimensions)\n",
    "        input_shape = backend.int_shape(input_tensor)\n",
    "        spatial_size = input_shape[1:3] if backend.image_data_format() == 'channels_last' else input_shape[2:]\n",
    "\n",
    "        # Compute the kernel and stride sizes according to how large the final feature map will be\n",
    "        # When the kernel factor and strides are equal, then we can compute the final feature map factor\n",
    "        # by simply dividing the current factor by the kernel or stride factor\n",
    "        # The final feature map sizes are 1x1, 2x2, 3x3, and 6x6.\n",
    "        pool_size = up_size = [spatial_size[0] // level, spatial_size[1] // level]\n",
    "\n",
    "        x = Pooling2D(pool_size, strides=pool_size, padding='same', name=pooling_name)(input_tensor)\n",
    "        x = Conv1x1BnReLU(conv_filters, use_batchnorm, name=conv_block_name)(x)\n",
    "        x = layers.UpSampling2D(up_size, interpolation='bilinear', name=upsampling_name)(x)\n",
    "        return x\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  PSP Decoder\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def build_psp(\n",
    "        backbone,\n",
    "        psp_layer_idx,\n",
    "        pooling_type='avg',\n",
    "        conv_filters=512,\n",
    "        use_batchnorm=True,\n",
    "        final_upsampling_factor=8,\n",
    "        classes=21,\n",
    "        activation='softmax',\n",
    "        dropout=None,\n",
    "):\n",
    "    input_ = backbone.input\n",
    "    x = (backbone.get_layer(name=psp_layer_idx).output if isinstance(psp_layer_idx, str)\n",
    "         else backbone.get_layer(index=psp_layer_idx).output)\n",
    "\n",
    "    # build spatial pyramid\n",
    "    x1 = SpatialContextBlock(1, conv_filters, pooling_type, use_batchnorm)(x)\n",
    "    x2 = SpatialContextBlock(2, conv_filters, pooling_type, use_batchnorm)(x)\n",
    "    x3 = SpatialContextBlock(3, conv_filters, pooling_type, use_batchnorm)(x)\n",
    "    x6 = SpatialContextBlock(6, conv_filters, pooling_type, use_batchnorm)(x)\n",
    "\n",
    "    # aggregate spatial pyramid\n",
    "    concat_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    x = layers.Concatenate(axis=concat_axis, name='psp_concat')([x, x1, x2, x3, x6])\n",
    "    x = Conv1x1BnReLU(conv_filters, use_batchnorm, name='aggregation')(x)\n",
    "\n",
    "    # model regularization\n",
    "    if dropout is not None:\n",
    "        x = layers.SpatialDropout2D(dropout, name='spatial_dropout')(x)\n",
    "\n",
    "    # model head\n",
    "    x = layers.Conv2D(\n",
    "        filters=classes,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        name='final_conv',\n",
    "    )(x)\n",
    "\n",
    "    x = layers.UpSampling2D(final_upsampling_factor, name='final_upsampling', interpolation='bilinear')(x)\n",
    "    x = layers.Activation(activation, name=activation)(x)\n",
    "\n",
    "    model = models.Model(input_, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  PSP Model\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def PSPNet(\n",
    "        backbone_name='vgg16',\n",
    "        input_shape=(384, 384, 3),\n",
    "        classes=21,\n",
    "        activation='softmax',\n",
    "        weights=None,\n",
    "        encoder_weights='imagenet',\n",
    "        encoder_freeze=False,\n",
    "        downsample_factor=8,\n",
    "        psp_conv_filters=512,\n",
    "        psp_pooling_type='avg',\n",
    "        psp_use_batchnorm=True,\n",
    "        psp_dropout=None,\n",
    "        **kwargs\n",
    "):\n",
    "    \"\"\"PSPNet_ is a fully convolution neural network for image semantic segmentation\n",
    "    Args:\n",
    "        backbone_name: name of classification model used as feature\n",
    "                extractor to build segmentation model.\n",
    "        input_shape: shape of input data/image ``(H, W, C)``.\n",
    "            ``H`` and ``W`` should be divisible by ``6 * downsample_factor`` and **NOT** ``None``!\n",
    "        classes: a number of classes for output (output shape - ``(h, w, classes)``).\n",
    "        activation: name of one of ``keras.activations`` for last model layer\n",
    "                (e.g. ``sigmoid``, ``softmax``, ``linear``).\n",
    "        weights: optional, path to model weights.\n",
    "        encoder_weights: one of ``None`` (random initialization), ``imagenet`` (pre-training on ImageNet).\n",
    "        encoder_freeze: if ``True`` set all layers of encoder (backbone model) as non-trainable.\n",
    "        downsample_factor: one of 4, 8 and 16. Downsampling rate or in other words backbone depth\n",
    "            to construct PSP module on it.\n",
    "        psp_conv_filters: number of filters in ``Conv2D`` layer in each PSP block.\n",
    "        psp_pooling_type: one of 'avg', 'max'. PSP block pooling type (maximum or average).\n",
    "        psp_use_batchnorm: if ``True``, ``BatchNormalisation`` layer between ``Conv2D`` and ``Activation`` layers\n",
    "                is used.\n",
    "        psp_dropout: dropout rate between 0 and 1.\n",
    "    Returns:\n",
    "        ``keras.models.Model``: **PSPNet**\n",
    "    .. _PSPNet:\n",
    "        https://arxiv.org/pdf/1612.01105.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    global backend, layers, models, keras_utils\n",
    "    submodule_args = filter_keras_submodules(kwargs)\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(submodule_args)\n",
    "\n",
    "    # control image input shape\n",
    "    check_input_shape(input_shape, downsample_factor)\n",
    "\n",
    "    backbone = Backbones.get_backbone(\n",
    "        backbone_name,\n",
    "        input_shape=input_shape,\n",
    "        weights=encoder_weights,\n",
    "        include_top=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    feature_layers = Backbones.get_feature_layers(backbone_name, n=3)\n",
    "\n",
    "    if downsample_factor == 16:\n",
    "        psp_layer_idx = feature_layers[0]\n",
    "    elif downsample_factor == 8:\n",
    "        psp_layer_idx = feature_layers[1]\n",
    "    elif downsample_factor == 4:\n",
    "        psp_layer_idx = feature_layers[2]\n",
    "    else:\n",
    "        raise ValueError('Unsupported factor - `{}`, Use 4, 8 or 16.'.format(downsample_factor))\n",
    "\n",
    "    model = build_psp(\n",
    "        backbone,\n",
    "        psp_layer_idx,\n",
    "        pooling_type=psp_pooling_type,\n",
    "        conv_filters=psp_conv_filters,\n",
    "        use_batchnorm=psp_use_batchnorm,\n",
    "        final_upsampling_factor=downsample_factor,\n",
    "        classes=classes,\n",
    "        activation=activation,\n",
    "        dropout=psp_dropout,\n",
    "    )\n",
    "\n",
    "    # lock encoder weights for fine-tuning\n",
    "    if encoder_freeze:\n",
    "        freeze_model(backbone, **kwargs)\n",
    "\n",
    "    # loading model weights\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05d2d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of the training, validation and testing will be saved to:results_trial6\n",
      "The dataset is already downloaded and the cross-validation folds were created!\n",
      "Starting the cross-validation!!\n",
      "Working on fold #0, starting training U-Net\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Found 1818 images belonging to 1 classes.\n",
      "Found 1818 images belonging to 1 classes.\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.9191 - jaccard_loss: 0.9454Found 520 images belonging to 1 classes.\n",
      "Found 520 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: val_jaccard_loss improved from inf to 0.96822, saving model to results_trial6\\unet_CV0.hdf5\n",
      "56/56 [==============================] - 58s 1s/step - loss: 0.6946 - accuracy: 0.9191 - jaccard_loss: 0.9454 - val_loss: 0.6930 - val_accuracy: 0.9651 - val_jaccard_loss: 0.9682\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.9421 - jaccard_loss: 0.9459\n",
      "Epoch 2: val_jaccard_loss improved from 0.96822 to 0.96812, saving model to results_trial6\\unet_CV0.hdf5\n",
      "56/56 [==============================] - 55s 1s/step - loss: 0.6928 - accuracy: 0.9421 - jaccard_loss: 0.9459 - val_loss: 0.6927 - val_accuracy: 0.9658 - val_jaccard_loss: 0.9681\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.9414 - jaccard_loss: 0.9451\n",
      "Epoch 3: val_jaccard_loss did not improve from 0.96812\n",
      "56/56 [==============================] - 55s 997ms/step - loss: 0.6925 - accuracy: 0.9414 - jaccard_loss: 0.9451 - val_loss: 0.6924 - val_accuracy: 0.9661 - val_jaccard_loss: 0.9683\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.9406 - jaccard_loss: 0.9443\n",
      "Epoch 4: val_jaccard_loss improved from 0.96812 to 0.96808, saving model to results_trial6\\unet_CV0.hdf5\n",
      "56/56 [==============================] - 55s 998ms/step - loss: 0.6923 - accuracy: 0.9406 - jaccard_loss: 0.9443 - val_loss: 0.6921 - val_accuracy: 0.9662 - val_jaccard_loss: 0.9681\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.9405 - jaccard_loss: 0.9442\n",
      "Epoch 5: val_jaccard_loss did not improve from 0.96808\n",
      "56/56 [==============================] - 55s 993ms/step - loss: 0.6920 - accuracy: 0.9405 - jaccard_loss: 0.9442 - val_loss: 0.6919 - val_accuracy: 0.9664 - val_jaccard_loss: 0.9681\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.9419 - jaccard_loss: 0.9454\n",
      "Epoch 6: val_jaccard_loss improved from 0.96808 to 0.96807, saving model to results_trial6\\unet_CV0.hdf5\n",
      "56/56 [==============================] - 55s 997ms/step - loss: 0.6918 - accuracy: 0.9419 - jaccard_loss: 0.9454 - val_loss: 0.6916 - val_accuracy: 0.9665 - val_jaccard_loss: 0.9681\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.9397 - jaccard_loss: 0.9434\n",
      "Epoch 7: val_jaccard_loss did not improve from 0.96807\n",
      "56/56 [==============================] - 54s 981ms/step - loss: 0.6916 - accuracy: 0.9397 - jaccard_loss: 0.9434 - val_loss: 0.6913 - val_accuracy: 0.9666 - val_jaccard_loss: 0.9681\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.9437 - jaccard_loss: 0.9470\n",
      "Epoch 8: val_jaccard_loss improved from 0.96807 to 0.96797, saving model to results_trial6\\unet_CV0.hdf5\n",
      "56/56 [==============================] - 56s 1s/step - loss: 0.6913 - accuracy: 0.9437 - jaccard_loss: 0.9470 - val_loss: 0.6911 - val_accuracy: 0.9666 - val_jaccard_loss: 0.9680\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.9406 - jaccard_loss: 0.9441\n",
      "Epoch 9: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 55s 997ms/step - loss: 0.6911 - accuracy: 0.9406 - jaccard_loss: 0.9441 - val_loss: 0.6908 - val_accuracy: 0.9667 - val_jaccard_loss: 0.9680\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.9426 - jaccard_loss: 0.9458\n",
      "Epoch 10: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 55s 994ms/step - loss: 0.6908 - accuracy: 0.9426 - jaccard_loss: 0.9458 - val_loss: 0.6905 - val_accuracy: 0.9668 - val_jaccard_loss: 0.9683\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.9422 - jaccard_loss: 0.9455\n",
      "Epoch 11: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 55s 992ms/step - loss: 0.6906 - accuracy: 0.9422 - jaccard_loss: 0.9455 - val_loss: 0.6903 - val_accuracy: 0.9668 - val_jaccard_loss: 0.9680\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.9394 - jaccard_loss: 0.9430\n",
      "Epoch 12: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 55s 988ms/step - loss: 0.6903 - accuracy: 0.9394 - jaccard_loss: 0.9430 - val_loss: 0.6900 - val_accuracy: 0.9668 - val_jaccard_loss: 0.9681\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.9420 - jaccard_loss: 0.9454\n",
      "Epoch 13: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 54s 980ms/step - loss: 0.6901 - accuracy: 0.9420 - jaccard_loss: 0.9454 - val_loss: 0.6898 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9682\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.9424 - jaccard_loss: 0.9459\n",
      "Epoch 14: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 54s 980ms/step - loss: 0.6898 - accuracy: 0.9424 - jaccard_loss: 0.9459 - val_loss: 0.6895 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9681\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.9404 - jaccard_loss: 0.9440\n",
      "Epoch 15: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 54s 983ms/step - loss: 0.6896 - accuracy: 0.9404 - jaccard_loss: 0.9440 - val_loss: 0.6892 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9681\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.9422 - jaccard_loss: 0.9455\n",
      "Epoch 16: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 54s 982ms/step - loss: 0.6893 - accuracy: 0.9422 - jaccard_loss: 0.9455 - val_loss: 0.6890 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9681\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.9395 - jaccard_loss: 0.9431\n",
      "Epoch 17: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 55s 995ms/step - loss: 0.6891 - accuracy: 0.9395 - jaccard_loss: 0.9431 - val_loss: 0.6887 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9682\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.9422 - jaccard_loss: 0.9455\n",
      "Epoch 18: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 56s 1s/step - loss: 0.6888 - accuracy: 0.9422 - jaccard_loss: 0.9455 - val_loss: 0.6885 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9680\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.9424 - jaccard_loss: 0.9457\n",
      "Epoch 19: val_jaccard_loss did not improve from 0.96797\n",
      "56/56 [==============================] - 55s 993ms/step - loss: 0.6886 - accuracy: 0.9424 - jaccard_loss: 0.9457 - val_loss: 0.6882 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.9421 - jaccard_loss: 0.9455\n",
      "Epoch 20: val_jaccard_loss improved from 0.96797 to 0.96786, saving model to results_trial6\\unet_CV0.hdf5\n",
      "56/56 [==============================] - 56s 1s/step - loss: 0.6883 - accuracy: 0.9421 - jaccard_loss: 0.9455 - val_loss: 0.6879 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9679\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.9413 - jaccard_loss: 0.9447\n",
      "Epoch 21: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 994ms/step - loss: 0.6881 - accuracy: 0.9413 - jaccard_loss: 0.9447 - val_loss: 0.6877 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.9412 - jaccard_loss: 0.9447\n",
      "Epoch 22: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 1s/step - loss: 0.6879 - accuracy: 0.9412 - jaccard_loss: 0.9447 - val_loss: 0.6874 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9680\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.9421 - jaccard_loss: 0.9455\n",
      "Epoch 23: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 991ms/step - loss: 0.6876 - accuracy: 0.9421 - jaccard_loss: 0.9455 - val_loss: 0.6872 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9680\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.9428 - jaccard_loss: 0.9460\n",
      "Epoch 24: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 989ms/step - loss: 0.6874 - accuracy: 0.9428 - jaccard_loss: 0.9460 - val_loss: 0.6869 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9682\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.9413 - jaccard_loss: 0.9448\n",
      "Epoch 25: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 994ms/step - loss: 0.6871 - accuracy: 0.9413 - jaccard_loss: 0.9448 - val_loss: 0.6867 - val_accuracy: 0.9669 - val_jaccard_loss: 0.9681\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.9407 - jaccard_loss: 0.9443\n",
      "Epoch 26: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 992ms/step - loss: 0.6869 - accuracy: 0.9407 - jaccard_loss: 0.9443 - val_loss: 0.6864 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9680\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.9427 - jaccard_loss: 0.9460\n",
      "Epoch 27: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 990ms/step - loss: 0.6866 - accuracy: 0.9427 - jaccard_loss: 0.9460 - val_loss: 0.6861 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9680\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.9414 - jaccard_loss: 0.9448\n",
      "Epoch 28: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 56s 1s/step - loss: 0.6864 - accuracy: 0.9414 - jaccard_loss: 0.9448 - val_loss: 0.6859 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.9413 - jaccard_loss: 0.9447\n",
      "Epoch 29: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 57s 1s/step - loss: 0.6862 - accuracy: 0.9413 - jaccard_loss: 0.9447 - val_loss: 0.6856 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.9409 - jaccard_loss: 0.9445\n",
      "Epoch 30: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 57s 1s/step - loss: 0.6859 - accuracy: 0.9409 - jaccard_loss: 0.9445 - val_loss: 0.6854 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9682\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.9437 - jaccard_loss: 0.9470\n",
      "Epoch 31: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 57s 1s/step - loss: 0.6856 - accuracy: 0.9437 - jaccard_loss: 0.9470 - val_loss: 0.6851 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.9423 - jaccard_loss: 0.9457\n",
      "Epoch 32: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 55s 988ms/step - loss: 0.6854 - accuracy: 0.9423 - jaccard_loss: 0.9457 - val_loss: 0.6848 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.9390 - jaccard_loss: 0.9427\n",
      "Epoch 33: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 982ms/step - loss: 0.6852 - accuracy: 0.9390 - jaccard_loss: 0.9427 - val_loss: 0.6846 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.9444 - jaccard_loss: 0.9476\n",
      "Epoch 34: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 984ms/step - loss: 0.6849 - accuracy: 0.9444 - jaccard_loss: 0.9476 - val_loss: 0.6843 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.9412 - jaccard_loss: 0.9446\n",
      "Epoch 35: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 982ms/step - loss: 0.6847 - accuracy: 0.9412 - jaccard_loss: 0.9446 - val_loss: 0.6841 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9679\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.9414 - jaccard_loss: 0.9449\n",
      "Epoch 36: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 983ms/step - loss: 0.6845 - accuracy: 0.9414 - jaccard_loss: 0.9449 - val_loss: 0.6838 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9682\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.9425 - jaccard_loss: 0.9459\n",
      "Epoch 37: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 982ms/step - loss: 0.6842 - accuracy: 0.9425 - jaccard_loss: 0.9459 - val_loss: 0.6836 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9682\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.9404 - jaccard_loss: 0.9439\n",
      "Epoch 38: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 981ms/step - loss: 0.6840 - accuracy: 0.9404 - jaccard_loss: 0.9439 - val_loss: 0.6833 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9681\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.9416 - jaccard_loss: 0.9451\n",
      "Epoch 39: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 981ms/step - loss: 0.6837 - accuracy: 0.9416 - jaccard_loss: 0.9451 - val_loss: 0.6830 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9682\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6835 - accuracy: 0.9395 - jaccard_loss: 0.9432\n",
      "Epoch 40: val_jaccard_loss did not improve from 0.96786\n",
      "56/56 [==============================] - 54s 982ms/step - loss: 0.6835 - accuracy: 0.9395 - jaccard_loss: 0.9432 - val_loss: 0.6828 - val_accuracy: 0.9670 - val_jaccard_loss: 0.9682\n",
      "Testing the best U-Net model on testing data and saving the results to: results_trial6\\crops\\CV0\n",
      "28273/28273 [==============================] - 200s 7ms/step\n",
      "Combining the crops masks to find the full CT mask after performing morphological operations and saving the results to: results_trial6\\fullCT_original\\CV0\n",
      "Working on fold #1, starting training U-Net\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Found 1818 images belonging to 1 classes.\n",
      "Found 1818 images belonging to 1 classes.\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.8363 - jaccard_loss: 0.9677Found 651 images belonging to 1 classes.\n",
      "Found 651 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: val_jaccard_loss improved from inf to 0.96365, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 68s 1s/step - loss: 0.4303 - accuracy: 0.8363 - jaccard_loss: 0.9677 - val_loss: 0.3452 - val_accuracy: 0.9497 - val_jaccard_loss: 0.9637\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.9389 - jaccard_loss: 0.9578\n",
      "Epoch 2: val_jaccard_loss improved from 0.96365 to 0.95287, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.2470 - accuracy: 0.9389 - jaccard_loss: 0.9578 - val_loss: 0.3092 - val_accuracy: 0.9572 - val_jaccard_loss: 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9415 - jaccard_loss: 0.9357\n",
      "Epoch 3: val_jaccard_loss improved from 0.95287 to 0.94462, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.2053 - accuracy: 0.9415 - jaccard_loss: 0.9357 - val_loss: 0.3089 - val_accuracy: 0.9575 - val_jaccard_loss: 0.9446\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9408 - jaccard_loss: 0.9117\n",
      "Epoch 4: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1863 - accuracy: 0.9408 - jaccard_loss: 0.9117 - val_loss: 0.3223 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9459\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9408 - jaccard_loss: 0.8918\n",
      "Epoch 5: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1727 - accuracy: 0.9408 - jaccard_loss: 0.8918 - val_loss: 0.3274 - val_accuracy: 0.9478 - val_jaccard_loss: 0.9470\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9426 - jaccard_loss: 0.8791\n",
      "Epoch 6: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 64s 1s/step - loss: 0.1612 - accuracy: 0.9426 - jaccard_loss: 0.8791 - val_loss: 0.3219 - val_accuracy: 0.9508 - val_jaccard_loss: 0.9517\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9422 - jaccard_loss: 0.8592\n",
      "Epoch 7: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1564 - accuracy: 0.9422 - jaccard_loss: 0.8592 - val_loss: 0.3101 - val_accuracy: 0.9186 - val_jaccard_loss: 0.9524\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9495 - jaccard_loss: 0.8412\n",
      "Epoch 8: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1402 - accuracy: 0.9495 - jaccard_loss: 0.8412 - val_loss: 0.3001 - val_accuracy: 0.9222 - val_jaccard_loss: 0.9572\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9500 - jaccard_loss: 0.8094\n",
      "Epoch 9: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1330 - accuracy: 0.9500 - jaccard_loss: 0.8094 - val_loss: 0.2990 - val_accuracy: 0.8919 - val_jaccard_loss: 0.9564\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9545 - jaccard_loss: 0.7920\n",
      "Epoch 10: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 64s 1s/step - loss: 0.1260 - accuracy: 0.9545 - jaccard_loss: 0.7920 - val_loss: 0.2641 - val_accuracy: 0.9145 - val_jaccard_loss: 0.9508\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9569 - jaccard_loss: 0.7608\n",
      "Epoch 11: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1174 - accuracy: 0.9569 - jaccard_loss: 0.7608 - val_loss: 0.3865 - val_accuracy: 0.8037 - val_jaccard_loss: 0.9607\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9536 - jaccard_loss: 0.7623\n",
      "Epoch 12: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1286 - accuracy: 0.9536 - jaccard_loss: 0.7623 - val_loss: 0.2623 - val_accuracy: 0.9190 - val_jaccard_loss: 0.9490\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9598 - jaccard_loss: 0.7297\n",
      "Epoch 13: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1102 - accuracy: 0.9598 - jaccard_loss: 0.7297 - val_loss: 0.3304 - val_accuracy: 0.8546 - val_jaccard_loss: 0.9562\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9626 - jaccard_loss: 0.6904\n",
      "Epoch 14: val_jaccard_loss did not improve from 0.94462\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.1018 - accuracy: 0.9626 - jaccard_loss: 0.6904 - val_loss: 0.2965 - val_accuracy: 0.8775 - val_jaccard_loss: 0.9498\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9638 - jaccard_loss: 0.6605\n",
      "Epoch 15: val_jaccard_loss improved from 0.94462 to 0.94352, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0973 - accuracy: 0.9638 - jaccard_loss: 0.6605 - val_loss: 0.3339 - val_accuracy: 0.8453 - val_jaccard_loss: 0.9435\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9642 - jaccard_loss: 0.6636\n",
      "Epoch 16: val_jaccard_loss did not improve from 0.94352\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0982 - accuracy: 0.9642 - jaccard_loss: 0.6636 - val_loss: 0.3826 - val_accuracy: 0.8262 - val_jaccard_loss: 0.9570\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9649 - jaccard_loss: 0.6317\n",
      "Epoch 17: val_jaccard_loss did not improve from 0.94352\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0945 - accuracy: 0.9649 - jaccard_loss: 0.6317 - val_loss: 0.3473 - val_accuracy: 0.8582 - val_jaccard_loss: 0.9583\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9671 - jaccard_loss: 0.6270\n",
      "Epoch 18: val_jaccard_loss did not improve from 0.94352\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0896 - accuracy: 0.9671 - jaccard_loss: 0.6270 - val_loss: 0.4311 - val_accuracy: 0.7837 - val_jaccard_loss: 0.9541\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9691 - jaccard_loss: 0.6119\n",
      "Epoch 19: val_jaccard_loss improved from 0.94352 to 0.94036, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0855 - accuracy: 0.9691 - jaccard_loss: 0.6119 - val_loss: 0.2850 - val_accuracy: 0.8903 - val_jaccard_loss: 0.9404\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9699 - jaccard_loss: 0.5936\n",
      "Epoch 20: val_jaccard_loss improved from 0.94036 to 0.93996, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 6729s 122s/step - loss: 0.0826 - accuracy: 0.9699 - jaccard_loss: 0.5936 - val_loss: 0.3322 - val_accuracy: 0.8642 - val_jaccard_loss: 0.9400\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9711 - jaccard_loss: 0.5707\n",
      "Epoch 21: val_jaccard_loss improved from 0.93996 to 0.92489, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0789 - accuracy: 0.9711 - jaccard_loss: 0.5707 - val_loss: 0.2677 - val_accuracy: 0.9044 - val_jaccard_loss: 0.9249\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9713 - jaccard_loss: 0.5678\n",
      "Epoch 22: val_jaccard_loss did not improve from 0.92489\n",
      "56/56 [==============================] - 64s 1s/step - loss: 0.0798 - accuracy: 0.9713 - jaccard_loss: 0.5678 - val_loss: 0.3110 - val_accuracy: 0.8809 - val_jaccard_loss: 0.9407\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9719 - jaccard_loss: 0.5661\n",
      "Epoch 23: val_jaccard_loss did not improve from 0.92489\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0778 - accuracy: 0.9719 - jaccard_loss: 0.5661 - val_loss: 0.3147 - val_accuracy: 0.8661 - val_jaccard_loss: 0.9270\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9695 - jaccard_loss: 0.5864\n",
      "Epoch 24: val_jaccard_loss did not improve from 0.92489\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0849 - accuracy: 0.9695 - jaccard_loss: 0.5864 - val_loss: 0.3442 - val_accuracy: 0.8478 - val_jaccard_loss: 0.9302\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9727 - jaccard_loss: 0.5534\n",
      "Epoch 25: val_jaccard_loss improved from 0.92489 to 0.91645, saving model to results_trial6\\unet_CV1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 66s 1s/step - loss: 0.0755 - accuracy: 0.9727 - jaccard_loss: 0.5534 - val_loss: 0.2500 - val_accuracy: 0.9149 - val_jaccard_loss: 0.9164\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9736 - jaccard_loss: 0.5271\n",
      "Epoch 26: val_jaccard_loss did not improve from 0.91645\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0730 - accuracy: 0.9736 - jaccard_loss: 0.5271 - val_loss: 0.3208 - val_accuracy: 0.8690 - val_jaccard_loss: 0.9325\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9754 - jaccard_loss: 0.5077\n",
      "Epoch 27: val_jaccard_loss did not improve from 0.91645\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0680 - accuracy: 0.9754 - jaccard_loss: 0.5077 - val_loss: 0.3431 - val_accuracy: 0.8601 - val_jaccard_loss: 0.9367\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9730 - jaccard_loss: 0.5367\n",
      "Epoch 28: val_jaccard_loss did not improve from 0.91645\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0742 - accuracy: 0.9730 - jaccard_loss: 0.5367 - val_loss: 0.3184 - val_accuracy: 0.8789 - val_jaccard_loss: 0.9407\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9741 - jaccard_loss: 0.5202\n",
      "Epoch 29: val_jaccard_loss did not improve from 0.91645\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0722 - accuracy: 0.9741 - jaccard_loss: 0.5202 - val_loss: 0.4239 - val_accuracy: 0.8032 - val_jaccard_loss: 0.9409\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9745 - jaccard_loss: 0.5096\n",
      "Epoch 30: val_jaccard_loss did not improve from 0.91645\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0702 - accuracy: 0.9745 - jaccard_loss: 0.5096 - val_loss: 0.3156 - val_accuracy: 0.8769 - val_jaccard_loss: 0.9222\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9771 - jaccard_loss: 0.4931\n",
      "Epoch 31: val_jaccard_loss improved from 0.91645 to 0.90926, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0632 - accuracy: 0.9771 - jaccard_loss: 0.4931 - val_loss: 0.2756 - val_accuracy: 0.9037 - val_jaccard_loss: 0.9093\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9765 - jaccard_loss: 0.4894\n",
      "Epoch 32: val_jaccard_loss did not improve from 0.90926\n",
      "56/56 [==============================] - 67s 1s/step - loss: 0.0648 - accuracy: 0.9765 - jaccard_loss: 0.4894 - val_loss: 0.2902 - val_accuracy: 0.8868 - val_jaccard_loss: 0.9194\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9755 - jaccard_loss: 0.4796\n",
      "Epoch 33: val_jaccard_loss did not improve from 0.90926\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0670 - accuracy: 0.9755 - jaccard_loss: 0.4796 - val_loss: 0.3784 - val_accuracy: 0.8383 - val_jaccard_loss: 0.9240\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9775 - jaccard_loss: 0.4825\n",
      "Epoch 34: val_jaccard_loss improved from 0.90926 to 0.90040, saving model to results_trial6\\unet_CV1.hdf5\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0615 - accuracy: 0.9775 - jaccard_loss: 0.4825 - val_loss: 0.2701 - val_accuracy: 0.9045 - val_jaccard_loss: 0.9004\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9776 - jaccard_loss: 0.4659\n",
      "Epoch 35: val_jaccard_loss did not improve from 0.90040\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0616 - accuracy: 0.9776 - jaccard_loss: 0.4659 - val_loss: 0.3064 - val_accuracy: 0.8754 - val_jaccard_loss: 0.9053\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9760 - jaccard_loss: 0.4852\n",
      "Epoch 36: val_jaccard_loss did not improve from 0.90040\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0668 - accuracy: 0.9760 - jaccard_loss: 0.4852 - val_loss: 0.2782 - val_accuracy: 0.8947 - val_jaccard_loss: 0.9133\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9776 - jaccard_loss: 0.4712\n",
      "Epoch 37: val_jaccard_loss did not improve from 0.90040\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0608 - accuracy: 0.9776 - jaccard_loss: 0.4712 - val_loss: 0.2863 - val_accuracy: 0.8970 - val_jaccard_loss: 0.9137\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9776 - jaccard_loss: 0.4501\n",
      "Epoch 38: val_jaccard_loss did not improve from 0.90040\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0604 - accuracy: 0.9776 - jaccard_loss: 0.4501 - val_loss: 0.3589 - val_accuracy: 0.8470 - val_jaccard_loss: 0.9279\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9781 - jaccard_loss: 0.4615\n",
      "Epoch 39: val_jaccard_loss did not improve from 0.90040\n",
      "56/56 [==============================] - 65s 1s/step - loss: 0.0596 - accuracy: 0.9781 - jaccard_loss: 0.4615 - val_loss: 0.2844 - val_accuracy: 0.8987 - val_jaccard_loss: 0.9151\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9785 - jaccard_loss: 0.4418\n",
      "Epoch 40: val_jaccard_loss did not improve from 0.90040\n",
      "56/56 [==============================] - 66s 1s/step - loss: 0.0592 - accuracy: 0.9785 - jaccard_loss: 0.4418 - val_loss: 0.3737 - val_accuracy: 0.8451 - val_jaccard_loss: 0.9256\n",
      "Testing the best U-Net model on testing data and saving the results to: results_trial6\\crops\\CV1\n",
      "28665/28665 [==============================] - 200s 7ms/step\n",
      "Combining the crops masks to find the full CT mask after performing morphological operations and saving the results to: results_trial6\\fullCT_original\\CV1\n",
      "Working on fold #2, starting training U-Net\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Found 1920 images belonging to 1 classes.\n",
      "Found 1920 images belonging to 1 classes.\n",
      "Epoch 1/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.9141 - jaccard_loss: 0.9705Found 651 images belonging to 1 classes.\n",
      "Found 651 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: val_jaccard_loss improved from inf to 0.96220, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.3557 - accuracy: 0.9141 - jaccard_loss: 0.9705 - val_loss: 0.2771 - val_accuracy: 0.9569 - val_jaccard_loss: 0.9622\n",
      "Epoch 2/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.9491 - jaccard_loss: 0.9580\n",
      "Epoch 2: val_jaccard_loss improved from 0.96220 to 0.95156, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.2127 - accuracy: 0.9491 - jaccard_loss: 0.9580 - val_loss: 0.2823 - val_accuracy: 0.9574 - val_jaccard_loss: 0.9516\n",
      "Epoch 3/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9482 - jaccard_loss: 0.9346\n",
      "Epoch 3: val_jaccard_loss improved from 0.95156 to 0.95146, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1833 - accuracy: 0.9482 - jaccard_loss: 0.9346 - val_loss: 0.2504 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9515\n",
      "Epoch 4/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9489 - jaccard_loss: 0.9093\n",
      "Epoch 4: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.1616 - accuracy: 0.9489 - jaccard_loss: 0.9093 - val_loss: 0.2425 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9552\n",
      "Epoch 5/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9492 - jaccard_loss: 0.8847\n",
      "Epoch 5: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1477 - accuracy: 0.9492 - jaccard_loss: 0.8847 - val_loss: 0.2559 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9581\n",
      "Epoch 6/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9485 - jaccard_loss: 0.8528\n",
      "Epoch 6: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1326 - accuracy: 0.9485 - jaccard_loss: 0.8528 - val_loss: 0.2548 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9622\n",
      "Epoch 7/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9487 - jaccard_loss: 0.8439\n",
      "Epoch 7: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1312 - accuracy: 0.9487 - jaccard_loss: 0.8439 - val_loss: 0.2350 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9604\n",
      "Epoch 8/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9489 - jaccard_loss: 0.8310\n",
      "Epoch 8: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1224 - accuracy: 0.9489 - jaccard_loss: 0.8310 - val_loss: 0.2482 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9628\n",
      "Epoch 9/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9485 - jaccard_loss: 0.8009\n",
      "Epoch 9: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.1101 - accuracy: 0.9485 - jaccard_loss: 0.8009 - val_loss: 0.2369 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9583\n",
      "Epoch 10/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9477 - jaccard_loss: 0.7928\n",
      "Epoch 10: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1097 - accuracy: 0.9477 - jaccard_loss: 0.7928 - val_loss: 0.2590 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9579\n",
      "Epoch 11/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9489 - jaccard_loss: 0.7813\n",
      "Epoch 11: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1026 - accuracy: 0.9489 - jaccard_loss: 0.7813 - val_loss: 0.2392 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9587\n",
      "Epoch 12/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9498 - jaccard_loss: 0.7762\n",
      "Epoch 12: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0995 - accuracy: 0.9498 - jaccard_loss: 0.7762 - val_loss: 0.2643 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9606\n",
      "Epoch 13/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9491 - jaccard_loss: 0.7618\n",
      "Epoch 13: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0952 - accuracy: 0.9491 - jaccard_loss: 0.7618 - val_loss: 0.2761 - val_accuracy: 0.9575 - val_jaccard_loss: 0.9690\n",
      "Epoch 14/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9484 - jaccard_loss: 0.7574\n",
      "Epoch 14: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0958 - accuracy: 0.9484 - jaccard_loss: 0.7574 - val_loss: 0.2706 - val_accuracy: 0.9574 - val_jaccard_loss: 0.9646\n",
      "Epoch 15/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9559 - jaccard_loss: 0.7501\n",
      "Epoch 15: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0935 - accuracy: 0.9559 - jaccard_loss: 0.7501 - val_loss: 0.2305 - val_accuracy: 0.9099 - val_jaccard_loss: 0.9593\n",
      "Epoch 16/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9694 - jaccard_loss: 0.7457\n",
      "Epoch 16: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0929 - accuracy: 0.9694 - jaccard_loss: 0.7457 - val_loss: 0.2856 - val_accuracy: 0.8447 - val_jaccard_loss: 0.9611\n",
      "Epoch 17/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9716 - jaccard_loss: 0.7331\n",
      "Epoch 17: val_jaccard_loss did not improve from 0.95146\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0873 - accuracy: 0.9716 - jaccard_loss: 0.7331 - val_loss: 0.2568 - val_accuracy: 0.8894 - val_jaccard_loss: 0.9594\n",
      "Epoch 18/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9715 - jaccard_loss: 0.6932\n",
      "Epoch 18: val_jaccard_loss improved from 0.95146 to 0.94772, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0855 - accuracy: 0.9715 - jaccard_loss: 0.6932 - val_loss: 0.2821 - val_accuracy: 0.8853 - val_jaccard_loss: 0.9477\n",
      "Epoch 19/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9725 - jaccard_loss: 0.6005\n",
      "Epoch 19: val_jaccard_loss did not improve from 0.94772\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0766 - accuracy: 0.9725 - jaccard_loss: 0.6005 - val_loss: 0.3716 - val_accuracy: 0.8246 - val_jaccard_loss: 0.9552\n",
      "Epoch 20/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9727 - jaccard_loss: 0.5928\n",
      "Epoch 20: val_jaccard_loss improved from 0.94772 to 0.94490, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0759 - accuracy: 0.9727 - jaccard_loss: 0.5928 - val_loss: 0.3484 - val_accuracy: 0.8383 - val_jaccard_loss: 0.9449\n",
      "Epoch 21/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9735 - jaccard_loss: 0.5804\n",
      "Epoch 21: val_jaccard_loss did not improve from 0.94490\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0730 - accuracy: 0.9735 - jaccard_loss: 0.5804 - val_loss: 0.3770 - val_accuracy: 0.8375 - val_jaccard_loss: 0.9690\n",
      "Epoch 22/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9752 - jaccard_loss: 0.5712\n",
      "Epoch 22: val_jaccard_loss did not improve from 0.94490\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0700 - accuracy: 0.9752 - jaccard_loss: 0.5712 - val_loss: 0.3805 - val_accuracy: 0.8312 - val_jaccard_loss: 0.9526\n",
      "Epoch 23/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9754 - jaccard_loss: 0.5586\n",
      "Epoch 23: val_jaccard_loss did not improve from 0.94490\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0683 - accuracy: 0.9754 - jaccard_loss: 0.5586 - val_loss: 0.2687 - val_accuracy: 0.9025 - val_jaccard_loss: 0.9482\n",
      "Epoch 24/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9760 - jaccard_loss: 0.5369\n",
      "Epoch 24: val_jaccard_loss did not improve from 0.94490\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0667 - accuracy: 0.9760 - jaccard_loss: 0.5369 - val_loss: 0.3934 - val_accuracy: 0.8258 - val_jaccard_loss: 0.9464\n",
      "Epoch 25/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9757 - jaccard_loss: 0.5484\n",
      "Epoch 25: val_jaccard_loss improved from 0.94490 to 0.93758, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.0680 - accuracy: 0.9757 - jaccard_loss: 0.5484 - val_loss: 0.3746 - val_accuracy: 0.8360 - val_jaccard_loss: 0.9376\n",
      "Epoch 26/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9764 - jaccard_loss: 0.5312\n",
      "Epoch 26: val_jaccard_loss did not improve from 0.93758\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0651 - accuracy: 0.9764 - jaccard_loss: 0.5312 - val_loss: 0.3131 - val_accuracy: 0.8684 - val_jaccard_loss: 0.9447\n",
      "Epoch 27/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9759 - jaccard_loss: 0.5421\n",
      "Epoch 27: val_jaccard_loss improved from 0.93758 to 0.92876, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 70s 1s/step - loss: 0.0675 - accuracy: 0.9759 - jaccard_loss: 0.5421 - val_loss: 0.2788 - val_accuracy: 0.8843 - val_jaccard_loss: 0.9288\n",
      "Epoch 28/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9773 - jaccard_loss: 0.5218\n",
      "Epoch 28: val_jaccard_loss did not improve from 0.92876\n",
      "60/60 [==============================] - 87s 1s/step - loss: 0.0633 - accuracy: 0.9773 - jaccard_loss: 0.5218 - val_loss: 0.3636 - val_accuracy: 0.8420 - val_jaccard_loss: 0.9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9783 - jaccard_loss: 0.5097\n",
      "Epoch 29: val_jaccard_loss did not improve from 0.92876\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0604 - accuracy: 0.9783 - jaccard_loss: 0.5097 - val_loss: 0.3289 - val_accuracy: 0.8582 - val_jaccard_loss: 0.9326\n",
      "Epoch 30/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9779 - jaccard_loss: 0.5094\n",
      "Epoch 30: val_jaccard_loss improved from 0.92876 to 0.91616, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0617 - accuracy: 0.9779 - jaccard_loss: 0.5094 - val_loss: 0.2627 - val_accuracy: 0.8930 - val_jaccard_loss: 0.9162\n",
      "Epoch 31/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9771 - jaccard_loss: 0.5160\n",
      "Epoch 31: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0643 - accuracy: 0.9771 - jaccard_loss: 0.5160 - val_loss: 0.2931 - val_accuracy: 0.8775 - val_jaccard_loss: 0.9226\n",
      "Epoch 32/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9789 - jaccard_loss: 0.4974\n",
      "Epoch 32: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0592 - accuracy: 0.9789 - jaccard_loss: 0.4974 - val_loss: 0.3428 - val_accuracy: 0.8571 - val_jaccard_loss: 0.9395\n",
      "Epoch 33/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9787 - jaccard_loss: 0.4892\n",
      "Epoch 33: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0598 - accuracy: 0.9787 - jaccard_loss: 0.4892 - val_loss: 0.2956 - val_accuracy: 0.8830 - val_jaccard_loss: 0.9177\n",
      "Epoch 34/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9791 - jaccard_loss: 0.4947\n",
      "Epoch 34: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0578 - accuracy: 0.9791 - jaccard_loss: 0.4947 - val_loss: 0.3527 - val_accuracy: 0.8556 - val_jaccard_loss: 0.9454\n",
      "Epoch 35/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9785 - jaccard_loss: 0.4991\n",
      "Epoch 35: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0599 - accuracy: 0.9785 - jaccard_loss: 0.4991 - val_loss: 0.4192 - val_accuracy: 0.8184 - val_jaccard_loss: 0.9377\n",
      "Epoch 36/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9792 - jaccard_loss: 0.4852\n",
      "Epoch 36: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0577 - accuracy: 0.9792 - jaccard_loss: 0.4852 - val_loss: 0.2916 - val_accuracy: 0.8934 - val_jaccard_loss: 0.9259\n",
      "Epoch 37/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9798 - jaccard_loss: 0.4828\n",
      "Epoch 37: val_jaccard_loss did not improve from 0.91616\n",
      "60/60 [==============================] - 71s 1s/step - loss: 0.0560 - accuracy: 0.9798 - jaccard_loss: 0.4828 - val_loss: 0.3570 - val_accuracy: 0.8476 - val_jaccard_loss: 0.9216\n",
      "Epoch 38/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9791 - jaccard_loss: 0.4863\n",
      "Epoch 38: val_jaccard_loss improved from 0.91616 to 0.89932, saving model to results_trial6\\unet_CV2.hdf5\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0573 - accuracy: 0.9791 - jaccard_loss: 0.4863 - val_loss: 0.2473 - val_accuracy: 0.9099 - val_jaccard_loss: 0.8993\n",
      "Epoch 39/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9797 - jaccard_loss: 0.4757\n",
      "Epoch 39: val_jaccard_loss did not improve from 0.89932\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0563 - accuracy: 0.9797 - jaccard_loss: 0.4757 - val_loss: 0.2671 - val_accuracy: 0.9022 - val_jaccard_loss: 0.9244\n",
      "Epoch 40/40\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9801 - jaccard_loss: 0.4714\n",
      "Epoch 40: val_jaccard_loss did not improve from 0.89932\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0545 - accuracy: 0.9801 - jaccard_loss: 0.4714 - val_loss: 0.3765 - val_accuracy: 0.8404 - val_jaccard_loss: 0.9314\n",
      "Testing the best U-Net model on testing data and saving the results to: results_trial6\\crops\\CV2\n",
      "27391/27391 [==============================] - 191s 7ms/step\n",
      "Combining the crops masks to find the full CT mask after performing morphological operations and saving the results to: results_trial6\\fullCT_original\\CV2\n",
      "Working on fold #3, starting training U-Net\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Found 1693 images belonging to 1 classes.\n",
      "Found 1693 images belonging to 1 classes.\n",
      "Epoch 1/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.7755 - jaccard_loss: 0.9493Found 651 images belonging to 1 classes.\n",
      "Found 651 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: val_jaccard_loss improved from inf to 0.95941, saving model to results_trial6\\unet_CV3.hdf5\n",
      "52/52 [==============================] - 68s 1s/step - loss: 0.6956 - accuracy: 0.7755 - jaccard_loss: 0.9493 - val_loss: 0.6930 - val_accuracy: 0.9371 - val_jaccard_loss: 0.9594\n",
      "Epoch 2/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.9346 - jaccard_loss: 0.9498\n",
      "Epoch 2: val_jaccard_loss did not improve from 0.95941\n",
      "52/52 [==============================] - 76s 1s/step - loss: 0.6928 - accuracy: 0.9346 - jaccard_loss: 0.9498 - val_loss: 0.6927 - val_accuracy: 0.9516 - val_jaccard_loss: 0.9595\n",
      "Epoch 3/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.9419 - jaccard_loss: 0.9496\n",
      "Epoch 3: val_jaccard_loss did not improve from 0.95941\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.6926 - accuracy: 0.9419 - jaccard_loss: 0.9496 - val_loss: 0.6925 - val_accuracy: 0.9547 - val_jaccard_loss: 0.9594\n",
      "Epoch 4/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.9439 - jaccard_loss: 0.9492\n",
      "Epoch 4: val_jaccard_loss did not improve from 0.95941\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.6924 - accuracy: 0.9439 - jaccard_loss: 0.9492 - val_loss: 0.6922 - val_accuracy: 0.9560 - val_jaccard_loss: 0.9597\n",
      "Epoch 5/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.9467 - jaccard_loss: 0.9508\n",
      "Epoch 5: val_jaccard_loss did not improve from 0.95941\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.6921 - accuracy: 0.9467 - jaccard_loss: 0.9508 - val_loss: 0.6920 - val_accuracy: 0.9565 - val_jaccard_loss: 0.9596\n",
      "Epoch 6/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.9463 - jaccard_loss: 0.9499\n",
      "Epoch 6: val_jaccard_loss improved from 0.95941 to 0.95937, saving model to results_trial6\\unet_CV3.hdf5\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6919 - accuracy: 0.9463 - jaccard_loss: 0.9499 - val_loss: 0.6917 - val_accuracy: 0.9568 - val_jaccard_loss: 0.9594\n",
      "Epoch 7/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.9464 - jaccard_loss: 0.9498\n",
      "Epoch 7: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6916 - accuracy: 0.9464 - jaccard_loss: 0.9498 - val_loss: 0.6915 - val_accuracy: 0.9571 - val_jaccard_loss: 0.9596\n",
      "Epoch 8/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.9450 - jaccard_loss: 0.9484\n",
      "Epoch 8: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6914 - accuracy: 0.9450 - jaccard_loss: 0.9484 - val_loss: 0.6913 - val_accuracy: 0.9574 - val_jaccard_loss: 0.9597\n",
      "Epoch 9/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.9478 - jaccard_loss: 0.9508\n",
      "Epoch 9: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 68s 1s/step - loss: 0.6912 - accuracy: 0.9478 - jaccard_loss: 0.9508 - val_loss: 0.6910 - val_accuracy: 0.9574 - val_jaccard_loss: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.9467 - jaccard_loss: 0.9497\n",
      "Epoch 10: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.6910 - accuracy: 0.9467 - jaccard_loss: 0.9497 - val_loss: 0.6908 - val_accuracy: 0.9575 - val_jaccard_loss: 0.9595\n",
      "Epoch 11/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.9484 - jaccard_loss: 0.9513\n",
      "Epoch 11: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6907 - accuracy: 0.9484 - jaccard_loss: 0.9513 - val_loss: 0.6905 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9596\n",
      "Epoch 12/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.9463 - jaccard_loss: 0.9493\n",
      "Epoch 12: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6905 - accuracy: 0.9463 - jaccard_loss: 0.9493 - val_loss: 0.6903 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9595\n",
      "Epoch 13/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.9482 - jaccard_loss: 0.9510\n",
      "Epoch 13: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6902 - accuracy: 0.9482 - jaccard_loss: 0.9510 - val_loss: 0.6901 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9597\n",
      "Epoch 14/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.9446 - jaccard_loss: 0.9477\n",
      "Epoch 14: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6900 - accuracy: 0.9446 - jaccard_loss: 0.9477 - val_loss: 0.6898 - val_accuracy: 0.9576 - val_jaccard_loss: 0.9596\n",
      "Epoch 15/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.9483 - jaccard_loss: 0.9510\n",
      "Epoch 15: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.6898 - accuracy: 0.9483 - jaccard_loss: 0.9510 - val_loss: 0.6896 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9595\n",
      "Epoch 16/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.9470 - jaccard_loss: 0.9499\n",
      "Epoch 16: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.6896 - accuracy: 0.9470 - jaccard_loss: 0.9499 - val_loss: 0.6894 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9596\n",
      "Epoch 17/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.9465 - jaccard_loss: 0.9494\n",
      "Epoch 17: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6893 - accuracy: 0.9465 - jaccard_loss: 0.9494 - val_loss: 0.6891 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9596\n",
      "Epoch 18/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.9477 - jaccard_loss: 0.9505\n",
      "Epoch 18: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 72s 1s/step - loss: 0.6891 - accuracy: 0.9477 - jaccard_loss: 0.9505 - val_loss: 0.6889 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9596\n",
      "Epoch 19/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.9479 - jaccard_loss: 0.9507\n",
      "Epoch 19: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6889 - accuracy: 0.9479 - jaccard_loss: 0.9507 - val_loss: 0.6886 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9596\n",
      "Epoch 20/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.9464 - jaccard_loss: 0.9492\n",
      "Epoch 20: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.6886 - accuracy: 0.9464 - jaccard_loss: 0.9492 - val_loss: 0.6884 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9595\n",
      "Epoch 21/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.9483 - jaccard_loss: 0.9510\n",
      "Epoch 21: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6884 - accuracy: 0.9483 - jaccard_loss: 0.9510 - val_loss: 0.6882 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9595\n",
      "Epoch 22/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.9468 - jaccard_loss: 0.9497\n",
      "Epoch 22: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6882 - accuracy: 0.9468 - jaccard_loss: 0.9497 - val_loss: 0.6879 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9595\n",
      "Epoch 23/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.9472 - jaccard_loss: 0.9499\n",
      "Epoch 23: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6879 - accuracy: 0.9472 - jaccard_loss: 0.9499 - val_loss: 0.6877 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9596\n",
      "Epoch 24/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.9452 - jaccard_loss: 0.9482\n",
      "Epoch 24: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6877 - accuracy: 0.9452 - jaccard_loss: 0.9482 - val_loss: 0.6875 - val_accuracy: 0.9578 - val_jaccard_loss: 0.9596\n",
      "Epoch 25/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.9483 - jaccard_loss: 0.9510\n",
      "Epoch 25: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6875 - accuracy: 0.9483 - jaccard_loss: 0.9510 - val_loss: 0.6872 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9596\n",
      "Epoch 26/40\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.9469 - jaccard_loss: 0.9497\n",
      "Epoch 26: val_jaccard_loss did not improve from 0.95937\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.6873 - accuracy: 0.9469 - jaccard_loss: 0.9497 - val_loss: 0.6870 - val_accuracy: 0.9577 - val_jaccard_loss: 0.9596\n",
      "Epoch 27/40\n",
      "13/52 [======>.......................] - ETA: 10s - loss: 0.6871 - accuracy: 0.9510 - jaccard_loss: 0.9534"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 87>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    155\u001b[0m modelUnet \u001b[38;5;241m=\u001b[39m unet(learningRate\u001b[38;5;241m=\u001b[39mlearning_rateI,decayRate\u001b[38;5;241m=\u001b[39mdecayI, input_size \u001b[38;5;241m=\u001b[39m(windowLen,windowLen,\u001b[38;5;241m1\u001b[39m) )\n\u001b[0;32m    156\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;28mstr\u001b[39m(Path(SaveDir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet_CV\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(cvI)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m)), monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_jaccard_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    157\u001b[0m                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, period\u001b[38;5;241m=\u001b[39mNumEpochEval)\n\u001b[1;32m--> 158\u001b[0m history1\u001b[38;5;241m=\u001b[39m\u001b[43mmodelUnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainGener\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNumEpochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_imagesTrain\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalGener\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_imagesValidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(Path(SaveDir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory_CV\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(cvI)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m Results:  \u001b[38;5;66;03m# Python 3: open(..., 'wb')\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\n\u001b[0;32m    163\u001b[0m         [history1\u001b[38;5;241m.\u001b[39mhistory], Results)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np, os, pickle, cv2, glob\n",
    "from imageio import imread\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "from imageio import imsave\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "from prepare_data import *\n",
    "from data_process import *\n",
    "from model import *\n",
    "\n",
    "\n",
    "def Sens(y_true, y_pred):\n",
    "    cm1 = metrics.confusion_matrix(y_true, y_pred, labels=[1, 0])  # labels =[1,0] [positive [Hemorrhage], negative]\n",
    "    SensI = cm1[0, 0] / (cm1[0, 0] + cm1[0, 1])\n",
    "    return SensI  # TPR is also known as sensitivity\n",
    "\n",
    "def Speci(y_true, y_pred):\n",
    "    cm1 = metrics.confusion_matrix(y_true, y_pred, labels=[1, 0])  # labels =[1,0] [positive [Hemorrhage], negative]\n",
    "    SpeciI = cm1[1, 1] / (cm1[1, 0] + cm1[1, 1])\n",
    "    return SpeciI  # FPR is one minus the specificity or true negative rate\n",
    "\n",
    "def Jaccard_img(y_true, y_pred): #https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "    iou_score=0\n",
    "    counter=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if np.sum(y_true[i])>0:#Considering only the slices that have hemorrhage regions, if y_true is all zeros -> iou_score=nan.\n",
    "            im1 = np.asarray(y_true[i], dtype=bool)\n",
    "            im2 = np.asarray(y_pred[i], dtype=bool)\n",
    "            intersection = np.logical_and(im1, im2)\n",
    "            union = np.logical_or(im1, im2)\n",
    "            iou_score+= np.sum(intersection) / np.sum(union)\n",
    "            counter+=1\n",
    "    if counter>0:\n",
    "        return iou_score/counter\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def dice_img(y_true, y_pred):\n",
    "    dice=0\n",
    "    counter = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if np.sum(y_true[i]) > 0:  # Considering only the slices that have hemorrhage regions,\n",
    "            dice += dice_fun(y_true[i], y_pred[i])\n",
    "            counter += 1\n",
    "    if counter>0:\n",
    "        return dice/counter\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def dice_fun(im1, im2):\n",
    "    im1 = np.asarray(im1, dtype=bool)\n",
    "    im2 = np.asarray(im2, dtype=bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum())\n",
    "\n",
    "\n",
    "\n",
    "def testModel(model_path,test_path,save_path):\n",
    "    modelPSPnet = PSPnet(pretrained_weights=model_path, input_size =(windowLen,windowLen,1) )\n",
    "    testGener = testGenerator(test_path, target_size =(windowLen,windowLen,1))\n",
    "    testPredictions = modelPSPnet.predict(testGener,n_imagesTest,verbose=1)\n",
    "    saveResult(test_path,save_path,testPredictions) #sending the test image path so same name will be used for saving masks\n",
    "\n",
    "\n",
    "data_gen_args = dict(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    #brightness_range=(0,1.5),\n",
    "    fill_mode=\"nearest\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #############################################Training Parameters#######################################################\n",
    "    num_CV=5\n",
    "    #NumEpochs=100\n",
    "    NumEpochs= 40\n",
    "    NumEpochEval=1 #validated the model each NumEpochEval epochs\n",
    "    batch_size = 32\n",
    "    learning_rateI = 1e-5\n",
    "    decayI=learning_rateI/NumEpochs\n",
    "    detectionSen=20*20# labeling each slice as ICH if hemorrhage is detected in detectionSen pixels\n",
    "    thresholdI= 0.5\n",
    "    detectionThreshold=thresholdI*256  #threshold on detection probability\n",
    "    numSubj = 75\n",
    "    num_WindowsCT=49\n",
    "    imageLen = 512\n",
    "    windowLen = 128\n",
    "    strideLen = 64\n",
    "    num_Moves = int(imageLen/strideLen)-1\n",
    "    window_specs = [40, 120]  # Brain window\n",
    "    kernel_closing = np.ones((10, 10), np.uint8)\n",
    "    kernel_opening = np.ones((5, 5), np.uint8)# 5*5 in order not to delete thin hemorrhage\n",
    "\n",
    "    counterI=1; SaveDir = Path('results_trial'+str(counterI))\n",
    "    while(os.path.isdir(str(SaveDir))):\n",
    "        counterI+=1\n",
    "        SaveDir= Path('results_trial'+str(counterI))\n",
    "    os.mkdir(str(SaveDir))\n",
    "    os.mkdir(str(Path(SaveDir,'crops')))\n",
    "    os.mkdir(str(Path(SaveDir,'fullCT_original')))#Testing without morphological operations\n",
    "    os.mkdir(str(Path(SaveDir, 'fullCT_morph'+ str(thresholdI)))) #Testing with morphological operations\n",
    "    print('The results of the training, validation and testing will be saved to:'+ str(SaveDir))\n",
    "\n",
    "\n",
    "\n",
    "    #############################################Downloading and unzipping the dataset######################################\n",
    "    dataset_zip_dir='computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.3.1.zip'\n",
    "    crossvalid_dir='DataV1'\n",
    "    prepare_data(dataset_zip_dir, crossvalid_dir, numSubj, imageLen, windowLen, strideLen,\n",
    "                 num_Moves, window_specs) #preparing the data and saving it to ICH_DataSegmentV1.pkl\n",
    "\n",
    "    # Loading full image mask from the crops predictions\n",
    "    with open(str(Path(crossvalid_dir,'ICH_DataSegmentV1.pkl')), 'rb') as Dataset1:\n",
    "        [hemorrhageDiagnosisArray, AllCTscans, testMasks, subject_nums_shaffled] = pickle.load(Dataset1)\n",
    "    del AllCTscans\n",
    "    testMasks=np.uint8(testMasks)\n",
    "    testMasksAvg = np.where(np.sum(np.sum(testMasks, axis=1), axis=1) > detectionSen, 1, 0)  #\n",
    "    testPredictions=np.zeros((testMasks.shape[0],imageLen,imageLen),dtype=np.uint8) #predicted segmentation\n",
    "\n",
    "    ############################################Cross-validation############################################################\n",
    "    print('Starting the cross-validation!!')\n",
    "    for cvI in range(0,num_CV):\n",
    "        print(\"Working on fold #\" + str(cvI)+\", starting training U-Net\")\n",
    "        SaveDir_crops_cv=Path(SaveDir,'crops','CV'+str(cvI))\n",
    "        if os.path.isdir(str(SaveDir_crops_cv))==False:\n",
    "            os.mkdir(str(SaveDir_crops_cv))\n",
    "        SaveDir_full_cv=Path(SaveDir,'fullCT_original','CV'+str(cvI))\n",
    "        if os.path.isdir(str(SaveDir_full_cv))==False:\n",
    "            os.mkdir(str(SaveDir_full_cv))\n",
    "        SaveDir_cv = Path(SaveDir, 'fullCT_morph' + str(thresholdI), 'CV' + str(cvI))\n",
    "        if os.path.isdir(str(SaveDir_cv)) == False:\n",
    "            os.mkdir(str(SaveDir_cv))\n",
    "\n",
    "        dataDir = Path(crossvalid_dir,'CV'+str(cvI))\n",
    "        n_imagesTrain=len(glob.glob(os.path.join(str(Path(dataDir,'train','image')), \"*.png\")))\n",
    "        n_imagesValidate=len(glob.glob(os.path.join(str(Path(dataDir,'validate','image')), \"*.png\")))\n",
    "        n_imagesTest = len(glob.glob(os.path.join(str(Path(dataDir,'test','crops','image')), \"*.png\")))\n",
    "        trainGener = trainGenerator(batch_size,str(Path(dataDir,'train')),'image','label',data_gen_args,save_to_dir = None, target_size = (128,128))\n",
    "        valGener = validateGenerator(batch_size,str(Path(dataDir,'validate')), 'image', 'label', save_to_dir=None, target_size = (128,128))\n",
    "        modelPSPnet = PSPnet(learningRate=learning_rateI,decayRate=decayI, input_size =(windowLen,windowLen,1) )\n",
    "        model_checkpoint = ModelCheckpoint(str(Path(SaveDir,'PSPnet_CV'+str(cvI)+'.hdf5')), monitor='val_jaccard_loss', mode='min',\n",
    "                                           verbose=1, save_best_only=True, period=NumEpochEval)\n",
    "        history1=modelPSPnet.fit(trainGener,epochs=NumEpochs,steps_per_epoch=int(n_imagesTrain/batch_size),\n",
    "                                        validation_data=valGener,validation_steps=n_imagesValidate,callbacks=[model_checkpoint])\n",
    "\n",
    "        with open(str(Path(SaveDir,'history_CV'+str(cvI)+'.pkl')), 'wb') as Results:  # Python 3: open(..., 'wb')\n",
    "            pickle.dump(\n",
    "                [history1.history], Results)\n",
    "\n",
    "        #Loading and testing the model with lowest validation loss\n",
    "        print('Testing the best U-Net model on testing data and saving the results to: '+str(SaveDir_crops_cv))\n",
    "        testModel(str(Path(SaveDir, 'PSPnet_CV' + str(cvI) + '.hdf5')), str(Path(dataDir,'test','crops','image')),\n",
    "                      str(SaveDir_crops_cv))\n",
    "\n",
    "        #Creating full image mask from the crops predictions\n",
    "        if cvI < num_CV - 1:\n",
    "            subjectNums_cvI_testing = subject_nums_shaffled[cvI * int(numSubj / num_CV):cvI * int(numSubj / num_CV) + int(numSubj / num_CV)]\n",
    "        else:\n",
    "            subjectNums_cvI_testing = subject_nums_shaffled[cvI * int(numSubj / num_CV):numSubj]\n",
    "\n",
    "        #Finding the predictions or ICH segmentation for the whole slice\n",
    "        print('Combining the crops masks to find the full CT mask after performing morphological operations and saving the results to: ' + str(SaveDir_full_cv))\n",
    "        for subItest in range(0, len(subjectNums_cvI_testing)):\n",
    "            slicenum_s = hemorrhageDiagnosisArray[hemorrhageDiagnosisArray[:, 0] == subjectNums_cvI_testing[subItest], 1]\n",
    "            sliceInds = np.where(hemorrhageDiagnosisArray[:, 0] == subjectNums_cvI_testing[\n",
    "                subItest])  # using the slice index to keep the predictions have the same sequence as the ground truth.\n",
    "            counterSlice = 0\n",
    "            for sliceI in range(slicenum_s.size):\n",
    "                #reading the predicted segmentation for each window\n",
    "                CTslicePredict = np.zeros((imageLen, imageLen))\n",
    "                windowOcc = np.zeros((imageLen, imageLen))  # number of predictions for each pixel in the CT scan\n",
    "                counterCrop = 0\n",
    "                for i in range(num_Moves):\n",
    "                    for j in range(num_Moves):\n",
    "                        windowI = imread(Path(SaveDir_crops_cv,str(subjectNums_cvI_testing[subItest])\n",
    "                                      + '_' + str(sliceI) +'_'+ str(counterCrop)+ '.png'))\n",
    "                        windowI = windowI / 255\n",
    "                        CTslicePredict[int(i * imageLen / (num_Moves + 1)):int(i * imageLen / (num_Moves + 1) + windowLen),\n",
    "                            int(j * imageLen / (num_Moves + 1)):int(j * imageLen / (num_Moves + 1) + windowLen)]= CTslicePredict[int(i * imageLen / (num_Moves + 1)):int(i * imageLen / (num_Moves + 1) + windowLen),\n",
    "                            int(j * imageLen / (num_Moves + 1)):int(j * imageLen / (num_Moves + 1) + windowLen)]+windowI\n",
    "                        windowOcc[int(i * imageLen / (num_Moves + 1)):int(i * imageLen / (num_Moves + 1) + windowLen),\n",
    "                            int(j * imageLen / (num_Moves + 1)):int(j * imageLen / (num_Moves + 1) + windowLen)]= windowOcc[int(i * imageLen / (num_Moves + 1)):int(i * imageLen / (num_Moves + 1) + windowLen),\n",
    "                            int(j * imageLen / (num_Moves + 1)):int(j * imageLen / (num_Moves + 1) + windowLen)]+1\n",
    "                        counterCrop = counterCrop + 1\n",
    "                CTslicePredict=CTslicePredict / windowOcc *255\n",
    "                img=np.uint8(CTslicePredict)\n",
    "                imsave(Path(SaveDir_full_cv,str(subjectNums_cvI_testing[subItest])\n",
    "                                      + '_' + str(sliceI) + '.png'), img)\n",
    "\n",
    "                img = np.int16(np.where(img > detectionThreshold, 255, 0))\n",
    "                img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel_closing)  # Filling the gaps\n",
    "                img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_opening)\n",
    "                imsave(Path(SaveDir_cv,str(subjectNums_cvI_testing[subItest])\n",
    "                            + '_' + str(sliceI) + '.png'), np.uint8(img))\n",
    "                testPredictions[sliceInds[0][counterSlice]] = np.uint8(np.where(img > (0.5*256), 1, 0))\n",
    "                counterSlice+=1\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "    CVtestPredictionsAvg = np.where(np.sum(np.sum(testPredictions,axis=1),axis=1) > detectionSen, 1, 0) #\n",
    "\n",
    "    #Calculating the Final Testing Results for all CV iterations, results for pixel-wise classification\n",
    "    class_report=np.zeros((numSubj,14))\n",
    "    for subjI in range(numSubj):\n",
    "        sliceInds = np.where(hemorrhageDiagnosisArray[:, 0] == subjI)[0]\n",
    "        class_report[subjI,0]=Jaccard_img(testMasks[sliceInds],testPredictions[sliceInds])\n",
    "        class_report[subjI,1] = dice_img(testMasks[sliceInds], testPredictions[sliceInds])\n",
    "        #Results for slice-wise classification\n",
    "        class_report[subjI,2] = metrics.accuracy_score(testMasksAvg,CVtestPredictionsAvg)\n",
    "        class_report[subjI,3] = metrics.recall_score(testMasksAvg,CVtestPredictionsAvg, pos_label=1)\n",
    "        class_report[subjI,4] = metrics.precision_score(testMasksAvg,CVtestPredictionsAvg, pos_label=1)\n",
    "        class_report[subjI,5] = metrics.f1_score(testMasksAvg,CVtestPredictionsAvg, pos_label=1)\n",
    "        class_report[subjI,6] = Sens(testMasksAvg,CVtestPredictionsAvg)  # TPR is also known as sensitivity\n",
    "        class_report[subjI,7] = Speci(testMasksAvg,CVtestPredictionsAvg)  # FPR is one minus the specificity or true negative rate\n",
    "\n",
    "    class_report[21, :] = np.nan  \n",
    "    print(\"Final pixel-wise testing: mean Jaccard %.3f (max %.3f, min %.3f, +- %.3f), mean Dice %.3f (max %.3f, min %.3f, +- %.3f)\" % (\n",
    "            np.nanmean(class_report[:,0]), np.nanmax(class_report[:,0]),np.nanmin(class_report[:,0]),np.nanstd(class_report[:,0]),\n",
    "            np.nanmean(class_report[:,1]),np.nanmax(class_report[:,1]),np.nanmin(class_report[:,1]), np.nanstd(class_report[:,1])))\n",
    "    print(\"Final testing: Accuracy %.3f (max %.3f, min %.3f, +- %.3f), Sensi %.4f (max %.3f, min %.3f, +- %.3f), Speci %.4f (max %.3f, min %.3f, +- %.3f)).\" % (\n",
    "                np.nanmean(class_report[:,2]),np.nanmax(class_report[:,2]),np.nanmin(class_report[:,2]),np.nanstd(class_report[:,2])\n",
    "                ,np.nanmean(class_report[:,3]), np.nanmax(class_report[:,3]),np.nanmin(class_report[:,3]),np.nanstd(class_report[:,3])\n",
    "                ,np.nanmean(class_report[:,3]), np.nanmax(class_report[:,3]), np.nanmin(class_report[:,3]),np.nanstd(class_report[:,3])))\n",
    "\n",
    "    with open(str(Path(SaveDir,'fullCT_morph' + str(thresholdI),'report.pkl')), 'wb') as Results:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump(\n",
    "            [class_report, testMasks,testPredictions], Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37701e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess = get_preprocessing('resnet101') # for resnet, img = (img-110.0)/1.0\n",
    "\n",
    "# 'efficientnetb0'\n",
    "# 'densenet121'\n",
    "\n",
    "IMAGE_HEIGHT_ORIG = 650\n",
    "IMAGE_WIDTH_ORIG = 650\n",
    "\n",
    "NUM_TEST_IMAGES = 10 # 10 with intracranial hem + 10 without intracranial hem\n",
    "\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "BACKBONE = 'densenet121'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "\n",
    "# Note that the model takes 3-channel images as input\n",
    "model = PSPnet(BACKBONE, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), \n",
    "             #freeze_encoder=False,\n",
    "             classes=1, \n",
    "             encoder_weights='imagenet',\n",
    "             activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cc59f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = \"73_31.jpg\"\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "prd = Image.open('ms.png')\n",
    "prd1 = Image.open('ms2.png')\n",
    "msk1 = Image.open('74_20_HGE_Seg.jpg')\n",
    "msk2 = Image.open('73_31_HGE_Seg.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336b38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b315362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing import image\n",
    "img1 = \"73_31.jpg\"\n",
    "img = image.load_img(img1, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd7ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73de67a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(img_preprocessed)\n",
    "preds_test_thresh = (prediction >= 0.4).astype(np.uint8)\n",
    "preds_test_thresh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f51bba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b0f593eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a predicted mask\n",
    "indx = 0\n",
    "pred = preds_test_thresh[indx,:,:]\n",
    "plt.imshow(prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e74b3e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b0f6ec9d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(msk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a predicted mask\n",
    "indx = 1\n",
    "pred = preds_test_thresh[indx,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa78175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b0f776130>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dfdde60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b0f7b8ac0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(msk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbe914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
